{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1-BagOfWords.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMvexjtJn0wTG1mt7CzH+zK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1.Bag of Words"],"metadata":{"id":"nHNdo7sFOf9V"}},{"cell_type":"markdown","source":["Mètode per treure diferents **característiques** d’un text. \n","\n","Utilitzat per entrenaments per tal de crear **llista de vocabulari.**\n","\n","No es important l’ordre sinó les paraules úniques **que hi apareixen**. \n","\n"],"metadata":{"id":"mqhjEVxeOoeG"}},{"cell_type":"markdown","source":["Apart del processament de llenguatge natural també es utilitzat en **recuperació d’informació en textos** i **classificació d’aquests**.\n","\t\n","El resultat s’obté amb **vectors**, **poc òptim** si volem llistats de vocabulari extensos.\n"],"metadata":{"id":"cKVgFDygOxAi"}},{"cell_type":"markdown","source":["**El procés es el següent:**\n","\n","1.\tAgafem text \n","2.\tNetejar text\n","\n","3.\tTokenizació ( eliminació de les paraules stopword com signes puntuació)\n","\n","ignore = ['a', \"the\", \"is\"] \n","\n","4.\tGeneració de vocabulari\n","5.\tGeneració de vectors\n","\n","cleaned_text : ['joe', 'waited', 'for', 'train'] \n","Word List for Document :['for', 'joe', 'train', 'waited']\n","\n","Joe waited for the train\n","Vector = [1. 1. 1. 1.]\n","\n"],"metadata":{"id":"QnKckEu7O2U9"}},{"cell_type":"markdown","source":["Importació llibreries"],"metadata":{"id":"RYaOHhuWO96T"}},{"cell_type":"code","source":["import numpy\n","import re"],"metadata":{"id":"15z4xT5FPUIR","executionInfo":{"status":"ok","timestamp":1644404674793,"user_tz":-60,"elapsed":21,"user":{"displayName":"Maria Aguilà Pons","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRm_zuUb_WSCGVMjzEerhmasCkSW62hYlk4uwAcA=s64","userId":"00453553835455842846"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["frases a processar"],"metadata":{"id":"z6TJfAr_PXzt"}},{"cell_type":"code","source":["allsentences = [\"chandler waited for the car\", \"The bus was late\",\"Phoebe and Joe took the train\"]"],"metadata":{"id":"JiIKdZLxPapg","executionInfo":{"status":"ok","timestamp":1644404674794,"user_tz":-60,"elapsed":20,"user":{"displayName":"Maria Aguilà Pons","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRm_zuUb_WSCGVMjzEerhmasCkSW62hYlk4uwAcA=s64","userId":"00453553835455842846"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["neteja de les frases"],"metadata":{"id":"ICXyB6uwPdvh"}},{"cell_type":"code","source":["def word_extraction(sentence):\n","    ignore = ['a', \"the\", \"is\"]\n","    words = re.sub(\"[^\\w]\", \" \", sentence).split() #separa per paraules\n","    cleaned_text = [w.lower() for w in words if w not in ignore]\n","    return cleaned_text"],"metadata":{"id":"STpSxIqtPgn_","executionInfo":{"status":"ok","timestamp":1644404674795,"user_tz":-60,"elapsed":19,"user":{"displayName":"Maria Aguilà Pons","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRm_zuUb_WSCGVMjzEerhmasCkSW62hYlk4uwAcA=s64","userId":"00453553835455842846"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Tokenize ordenació en una llista"],"metadata":{"id":"5qn6ZKApPjeJ"}},{"cell_type":"code","source":["def tokenize(sentences):\n","    words = []\n","    for sentence in sentences:\n","        w = word_extraction(sentence)\n","        words.extend(w)\n","\n","    words = sorted(list(set(words)))\n","    return words"],"metadata":{"id":"OIQr067gPkDS","executionInfo":{"status":"ok","timestamp":1644404674795,"user_tz":-60,"elapsed":18,"user":{"displayName":"Maria Aguilà Pons","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRm_zuUb_WSCGVMjzEerhmasCkSW62hYlk4uwAcA=s64","userId":"00453553835455842846"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["gerenració funció Bag of words"],"metadata":{"id":"WtUieoQbPmyZ"}},{"cell_type":"code","source":["def generate_bow(allsentences):\n","    vocabulary = tokenize(allsentences)\n","    print(\"Word List for Document \\n{0} \\n\".format(vocabulary));\n","\n","    for sentence in allsentences:\n","        words = word_extraction(sentence)\n","        #cracio de vectors llargada de llista vocabulary\n","        bag_vector = numpy.zeros(len(vocabulary))\n","        for w in words:\n","            for i, word in enumerate(vocabulary):\n","                if word == w:\n","                    bag_vector[i] += 1\n","\n","        print(\"{0} \\n{1}\\n\".format(sentence, numpy.array(bag_vector)))\n"],"metadata":{"id":"Yh7ibFGvPnP2","executionInfo":{"status":"ok","timestamp":1644404674798,"user_tz":-60,"elapsed":20,"user":{"displayName":"Maria Aguilà Pons","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRm_zuUb_WSCGVMjzEerhmasCkSW62hYlk4uwAcA=s64","userId":"00453553835455842846"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["generate_bow(allsentences)"],"metadata":{"id":"ocCg2pbXPr2n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644404674799,"user_tz":-60,"elapsed":20,"user":{"displayName":"Maria Aguilà Pons","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjRm_zuUb_WSCGVMjzEerhmasCkSW62hYlk4uwAcA=s64","userId":"00453553835455842846"}},"outputId":"741e08c9-c638-4950-bd71-72ed0fcf8390"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Word List for Document \n","['and', 'bus', 'car', 'chandler', 'for', 'joe', 'late', 'phoebe', 'the', 'took', 'train', 'waited', 'was'] \n","\n","chandler waited for the car \n","[0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n","\n","The bus was late \n","[0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1.]\n","\n","Phoebe and Joe took the train \n","[1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.]\n","\n"]}]},{"cell_type":"markdown","source":["**Referencies:**\n","\n","An introduction to Bag of Words and how to code it in Python for NLP\n","https://www.freecodecamp.org/news/an-introduction-to-bag-of-words-and-how-to-code-it-in-python-for-nlp-282e87a9da04/\n","\n","Bag-of-words model - Wikipedia\n","https://en.wikipedia.org/wiki/Bag-of-words_model"],"metadata":{"id":"scZCBn-9-M7F"}}]}